{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e5aa4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5625, Training Accuracy: 0.6000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Predictions: [1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Set seeds for reproducibility (prevents random flipped predictions)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Step 1: Create the dataset (5 rows, 2 features: exercise_hours, water_intake)\n",
    "# Labels: 1 for healthy, 0 for not healthy\n",
    "data = np.array([\n",
    "    [2.0, 1.5],  # Row 1: 2 hours exercise, 1.5L water -> Healthy (1)\n",
    "    [0.5, 0.8],  # Row 2: 0.5 hours exercise, 0.8L water -> Not healthy (0)\n",
    "    [3.0, 2.0],  # Row 3: 3 hours exercise, 2.0L water -> Healthy (1)\n",
    "    [1.0, 1.0],  # Row 4: 1 hour exercise, 1.0L water -> Not healthy (0)\n",
    "    [2.5, 1.8]   # Row 5: 2.5 hours exercise, 1.8L water -> Healthy (1)\n",
    "])\n",
    "labels = np.array([1, 0, 1, 0, 1])  # Corresponding labels\n",
    "\n",
    "# Step 2: Normalize the features to [0, 1] for better ANN training\n",
    "scaler = MinMaxScaler()\n",
    "data_normalized = scaler.fit_transform(data)\n",
    "\n",
    "# Step 3: Define the ANN model (updated to use Input layer, avoiding deprecation warning)\n",
    "# - Input layer: Explicitly defined for 2 features\n",
    "# - Hidden layer: 4 neurons with ReLU activation\n",
    "# - Output layer: 1 neuron with sigmoid for binary classification\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(2,)),  # Explicit input layer (resolves warning)\n",
    "    tf.keras.layers.Dense(4, activation='relu'),  # Hidden layer\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Step 4: Compile the model\n",
    "# - Optimizer: Adam (efficient for small datasets)\n",
    "# - Loss: Binary cross-entropy (for binary classification)\n",
    "# - Metrics: Accuracy to track performance\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Train the model (increased epochs for better convergence)\n",
    "# - Epochs: 200 (more iterations for small data)\n",
    "# - Verbose: 0 to suppress output for brevity\n",
    "model.fit(data_normalized, labels, epochs=200, verbose=0)\n",
    "\n",
    "# Step 6: Evaluate the model on training data\n",
    "loss, accuracy = model.evaluate(data_normalized, labels, verbose=0)\n",
    "print(f\"Training Loss: {loss:.4f}, Training Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Step 7: Make predictions on the training data\n",
    "# - Threshold: 0.5 (sigmoid output > 0.5 -> 1, else 0)\n",
    "predictions = (model.predict(data_normalized) > 0.5).astype(int)\n",
    "print(\"Predictions:\", predictions.flatten())  # Should output: [1 0 1 0 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39b2e87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0055, Training Accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002112CFEC310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Predictions: [1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Set seeds for reproducibility (prevents random flipped predictions)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Step 1: Create the dataset (5 rows, 2 features: assignments_submitted, attendance_percentage)\n",
    "# Labels: 1 for pass, 0 for fail\n",
    "data = np.array([\n",
    "    [8, 85],   # Row 1: 8 assignments, 85% attendance -> Pass (1)\n",
    "    [3, 60],   # Row 2: 3 assignments, 60% attendance -> Fail (0)\n",
    "    [9, 90],   # Row 3: 9 assignments, 90% attendance -> Pass (1)\n",
    "    [5, 70],   # Row 4: 5 assignments, 70% attendance -> Fail (0)\n",
    "    [7, 80]    # Row 5: 7 assignments, 80% attendance -> Pass (1)\n",
    "])\n",
    "labels = np.array([1, 0, 1, 0, 1])  # Corresponding labels\n",
    "\n",
    "# Step 2: Normalize the features to [0, 1] for better ANN training\n",
    "scaler = MinMaxScaler()\n",
    "data_normalized = scaler.fit_transform(data)\n",
    "\n",
    "# Step 3: Define the ANN model (updated: more layers/neurons for better learning, Input layer to avoid warning)\n",
    "# - Input layer: Explicitly defined for 2 features\n",
    "# - Hidden layers: 8 neurons (first), 4 neurons (second) with ReLU\n",
    "# - Output layer: 1 neuron with sigmoid for binary classification\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(2,)),  # Explicit input layer (resolves warning)\n",
    "    tf.keras.layers.Dense(8, activation='relu'),  # First hidden layer (more neurons)\n",
    "    tf.keras.layers.Dense(4, activation='relu'),  # Second hidden layer\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Step 4: Compile the model (added learning rate for stability)\n",
    "# - Optimizer: Adam with lower learning rate (0.01)\n",
    "# - Loss: Binary cross-entropy (for binary classification)\n",
    "# - Metrics: Accuracy to track performance\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Train the model (increased epochs, added batch_size for small data)\n",
    "# - Epochs: 500 (more iterations for convergence)\n",
    "# - Batch size: 1 (process one sample at a time)\n",
    "# - Verbose: 0 to suppress output\n",
    "model.fit(data_normalized, labels, epochs=500, batch_size=1, verbose=0)\n",
    "\n",
    "# Step 6: Evaluate the model on training data\n",
    "loss, accuracy = model.evaluate(data_normalized, labels, verbose=0)\n",
    "print(f\"Training Loss: {loss:.4f}, Training Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Step 7: Make predictions on the training data\n",
    "# - Threshold: 0.5 (sigmoid output > 0.5 -> 1, else 0)\n",
    "predictions = (model.predict(data_normalized, verbose=0) > 0.5).astype(int)  # Added verbose=0 to reduce output\n",
    "print(\"Predictions:\", predictions.flatten())  # Should now output: [1 0 1 0 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edde75ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3313, Training Accuracy: 0.8000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "Predictions: [1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Set seeds for reproducibility (prevents random flipped predictions)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Step 1: Create the dataset (5 rows, 2 features: monthly_income, credit_score)\n",
    "# Labels: 1 for eligible, 0 for not eligible\n",
    "data = np.array([\n",
    "    [5000, 750],  # Row 1: $5000 income, 750 credit -> Eligible (1)\n",
    "    [2000, 600],  # Row 2: $2000 income, 600 credit -> Not eligible (0)\n",
    "    [6000, 800],  # Row 3: $6000 income, 800 credit -> Eligible (1)\n",
    "    [3000, 650],  # Row 4: $3000 income, 650 credit -> Not eligible (0)\n",
    "    [5500, 780]   # Row 5: $5500 income, 780 credit -> Eligible (1)\n",
    "])\n",
    "labels = np.array([1, 0, 1, 0, 1])  # Corresponding labels\n",
    "\n",
    "# Step 2: Normalize the features to [0, 1] for better ANN training\n",
    "scaler = MinMaxScaler()\n",
    "data_normalized = scaler.fit_transform(data)\n",
    "\n",
    "# Step 3: Define the ANN model (updated to use Input layer, avoiding deprecation warning)\n",
    "# - Input layer: Explicitly defined for 2 features\n",
    "# - Hidden layer: 4 neurons with ReLU activation\n",
    "# - Output layer: 1 neuron with sigmoid for binary classification\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(2,)),  # Explicit input layer (resolves warning)\n",
    "    tf.keras.layers.Dense(4, activation='relu'),  # Hidden layer\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Step 4: Compile the model\n",
    "# - Optimizer: Adam (efficient for small datasets)\n",
    "# - Loss: Binary cross-entropy (for binary classification)\n",
    "# - Metrics: Accuracy to track performance\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Train the model (increased epochs for better convergence)\n",
    "# - Epochs: 200 (more iterations for small data)\n",
    "# - Verbose: 0 to suppress output for brevity\n",
    "model.fit(data_normalized, labels, epochs=200, verbose=0)\n",
    "\n",
    "# Step 6: Evaluate the model on training data\n",
    "loss, accuracy = model.evaluate(data_normalized, labels, verbose=0)\n",
    "print(f\"Training Loss: {loss:.4f}, Training Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Step 7: Make predictions on the training data\n",
    "# - Threshold: 0.5 (sigmoid output > 0.5 -> 1, else 0)\n",
    "predictions = (model.predict(data_normalized) > 0.5).astype(int)\n",
    "print(\"Predictions:\", predictions.flatten())  # Should output: [1 0 1 0 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
